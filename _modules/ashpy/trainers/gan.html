

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ashpy.trainers.gan &mdash; AshPy 1.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> AshPy
          

          
          </a>

          
            
            
              <div class="version">
                1.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../home.html">AshPy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../home.html#set-up">Set up</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../home.html#ashpy-usage">AshPy usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../home.html#classifier">Classifier</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../home.html#gan-generative-adversarial-network">GAN - Generative Adversarial Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../home.html#dataset-output-format">Dataset Output Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../home.html#executor-context-metric-and-strategies">Executor, Context, Metric and Strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../write_the_docs.html">Write The Docs!</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../write_the_docs.html#the-whys">The Whys</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../write_the_docs.html#why-sphinx">Why Sphinx?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../write_the_docs.html#why-rest">Why reST?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../write_the_docs.html#why-google-style-for-docstrings">Why Google Style for Docstrings?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../write_the_docs.html#documentation-architecture">Documentation Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../write_the_docs.html#tutorials-guides-complex-examples">Tutorials, Guides, Complex Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../write_the_docs.html#api-reference">API Reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../write_the_docs.html#automate-all-the-docs">Automate all the docs!</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../write_the_docs.html#autosummary-submodules-with-imports-a-painful-story">Autosummary &amp; submodules with imports: A painful story</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../write_the_docs.html#inheritance-diagrams">Inheritance Diagrams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../write_the_docs.html#additional-materials">Additional Materials</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started.html#creating-a-new-dataset">Creating a new Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started.html#creating-a-new-model">Creating a new Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started.html#creating-a-new-trainer">Creating a new Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started.html#complete-examples">Complete Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../getting_started.html#classifier">Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting_started.html#gans">GANs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../getting_started.html#bigan">BiGAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting_started.html#mnist">MNIST</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/ashpy.models.html">ashpy.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/models/ashpy.models.convolutional.html">convolutional</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.interfaces.Conv2DInterface.html">Conv2DInterface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.decoders.BaseDecoder.html">BaseDecoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.decoders.FCNNBaseDecoder.html">FCNNBaseDecoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.encoders.BaseEncoder.html">BaseEncoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.encoders.FCNNBaseEncoder.html">FCNNBaseEncoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.convolutional.autoencoders.BaseAutoencoder.html">BaseAutoencoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.convolutional.autoencoders.FCNNBaseAutoencoder.html">FCNNBaseAutoencoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.unet.UNet.html">UNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.unet.SUNet.html">SUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.discriminators.MultiScaleDiscriminator.html">MultiScaleDiscriminator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.discriminators.PatchDiscriminator.html">PatchDiscriminator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.pix2pixhd.LocalEnhancer.html">LocalEnhancer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.pix2pixhd.GlobalGenerator.html">GlobalGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.interfaces.html">interfaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.decoders.html">decoders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.encoders.html">encoders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.autoencoders.html">autoencoders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.unet.html">unet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/convolutional/ashpy.models.convolutional.discriminators.html">discriminators</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/models/ashpy.models.fc.html">fc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.interfaces.FCInterface.html">FCInterface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.decoders.BaseDecoder.html">BaseDecoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.encoders.BaseEncoder.html">BaseEncoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.autoencoders.BaseAutoencoder.html">BaseAutoencoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.interfaces.html">interfaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.decoders.html">decoders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.encoders.html">encoders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/fc/ashpy.models.fc.autoencoders.html">autoencoders</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/models/ashpy.models.recurrent.html">recurrent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/models/ashpy.models.gans.html">gans</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/models/ashpy.models.gans.Generator.html">Generator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/models/ashpy.models.gans.Discriminator.html">Discriminator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/models/models/ashpy.models.gans.Encoder.html">Encoder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/ashpy.contexts.html">ashpy.contexts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.base_context.BaseContext.html">BaseContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.classifier.ClassifierContext.html">ClassifierContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.gan.GANContext.html">GANContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.gan.GANEncoderContext.html">GANEncoderContext</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.base_context.html">base_context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/contexts/base_context/ashpy.contexts.base_context.BaseContext.html">BaseContext</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.classifier.html">classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/contexts/classifier/ashpy.contexts.classifier.ClassifierContext.html">ClassifierContext</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/contexts/ashpy.contexts.gan.html">gan</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/contexts/gan/ashpy.contexts.gan.GANContext.html">GANContext</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/contexts/gan/ashpy.contexts.gan.GANEncoderContext.html">GANEncoderContext</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/ashpy.trainers.html">ashpy.trainers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/trainers/ashpy.trainers.BaseTrainer.html">BaseTrainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/trainers/ashpy.trainers.AdversarialTrainer.html">AdversarialTrainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/trainers/ashpy.trainers.EncoderTrainer.html">EncoderTrainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/trainers/ashpy.trainers.base_trainer.html">base_trainer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/trainers/base_trainer/ashpy.trainers.base_trainer.BaseTrainer.html">BaseTrainer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/trainers/ashpy.trainers.classifier.html">classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/trainers/classifier/ashpy.trainers.classifier.ClassifierTrainer.html">ClassifierTrainer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/trainers/ashpy.trainers.gan.html">gan</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html">AdversarialTrainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html">EncoderTrainer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/ashpy.layers.html">ashpy.layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/layers/ashpy.layers.layers.InstanceNormalization.html">InstanceNormalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/layers/ashpy.layers.layers.Attention.html">Attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/ashpy.losses.html">ashpy.losses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/executor/ashpy.losses.executor.Executor.html">Executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/executor/ashpy.losses.executor.SumExecutor.html">SumExecutor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/classifier/ashpy.losses.classifier.ClassifierLoss.html">ClassifierLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.AdversarialLossType.html">AdversarialLossType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.AdversarialLossG.html">AdversarialLossG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.AdversarialLossD.html">AdversarialLossD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.GeneratorBCE.html">GeneratorBCE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.GeneratorLSGAN.html">GeneratorLSGAN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.GeneratorL1.html">GeneratorL1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.FeatureMatchingLoss.html">FeatureMatchingLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.CategoricalCrossEntropy.html">CategoricalCrossEntropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.Pix2PixLoss.html">Pix2PixLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.Pix2PixLossSemantic.html">Pix2PixLossSemantic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.EncoderBCE.html">EncoderBCE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.DiscriminatorMinMax.html">DiscriminatorMinMax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.DiscriminatorLSGAN.html">DiscriminatorLSGAN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.get_adversarial_loss_discriminator.html">ashpy.losses.gan.get_adversarial_loss_discriminator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.losses.gan.get_adversarial_loss_generator.html">ashpy.losses.gan.get_adversarial_loss_generator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/losses/ashpy.losses.classifier.html">classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/classifier/ashpy.losses.classifier.ClassifierLoss.html">ClassifierLoss</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/losses/ashpy.losses.executor.html">executor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/executor/ashpy.losses.executor.Executor.html">Executor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/executor/ashpy.losses.executor.SumExecutor.html">SumExecutor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/losses/ashpy.losses.gan.html">gan</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.get_adversarial_loss_discriminator.html">ashpy.losses.gan.get_adversarial_loss_discriminator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.get_adversarial_loss_generator.html">ashpy.losses.gan.get_adversarial_loss_generator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.AdversarialLossD.html">AdversarialLossD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.AdversarialLossG.html">AdversarialLossG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.AdversarialLossType.html">AdversarialLossType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.CategoricalCrossEntropy.html">CategoricalCrossEntropy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.DiscriminatorLSGAN.html">DiscriminatorLSGAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.DiscriminatorMinMax.html">DiscriminatorMinMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.EncoderBCE.html">EncoderBCE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.FeatureMatchingLoss.html">FeatureMatchingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.GANExecutor.html">GANExecutor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.GeneratorBCE.html">GeneratorBCE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.GeneratorL1.html">GeneratorL1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.GeneratorLSGAN.html">GeneratorLSGAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.Pix2PixLoss.html">Pix2PixLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/losses/gan/ashpy.losses.gan.Pix2PixLossSemantic.html">Pix2PixLossSemantic</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../_autosummary/ashpy.metrics.html">ashpy.metrics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/metric/ashpy.metrics.metric.Metric.html">Metric</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/classifier/ashpy.metrics.classifier.ClassifierLoss.html">ClassifierLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/classifier/ashpy.metrics.classifier.ClassifierMetric.html">ClassifierMetric</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.metrics.gan.DiscriminatorLoss.html">DiscriminatorLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.metrics.gan.GeneratorLoss.html">GeneratorLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.metrics.gan.EncoderLoss.html">EncoderLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.metrics.gan.InceptionScore.html">InceptionScore</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/gan/ashpy.metrics.gan.EncodingAccuracy.html">EncodingAccuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/metrics/ashpy.metrics.classifier.html">classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/classifier/ashpy.metrics.classifier.ClassifierLoss.html">ClassifierLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/classifier/ashpy.metrics.classifier.ClassifierMetric.html">ClassifierMetric</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/metrics/ashpy.metrics.gan.html">gan</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/gan/ashpy.metrics.gan.DiscriminatorLoss.html">DiscriminatorLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/gan/ashpy.metrics.gan.EncoderLoss.html">EncoderLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/gan/ashpy.metrics.gan.EncodingAccuracy.html">EncodingAccuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/gan/ashpy.metrics.gan.GeneratorLoss.html">GeneratorLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/gan/ashpy.metrics.gan.InceptionScore.html">InceptionScore</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../_autosummary/metrics/ashpy.metrics.metric.html">metric</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/metrics/metric/ashpy.metrics.metric.Metric.html">Metric</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../dependencies_graph.html">Dependencies Graph</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dependencies_graph.html#ashpy-models">ashpy.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dependencies_graph.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dependencies_graph.html#gans">GANs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../dependencies_graph.html#ashpy-trainers">ashpy.trainers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dependencies_graph.html#adversarial">Adversarial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dependencies_graph.html#classifier">Classifier</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">AshPy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>ashpy.trainers.gan</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for ashpy.trainers.gan</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2019 Zuru Tech HK Limited. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;Collection of GANs trainers.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">ashpy.contexts.gan</span> <span class="k">import</span> <span class="n">GANContext</span><span class="p">,</span> <span class="n">GANEncoderContext</span>
<span class="kn">from</span> <span class="nn">ashpy.datasets</span> <span class="k">import</span> <span class="n">wrap</span>
<span class="kn">from</span> <span class="nn">ashpy.losses.executor</span> <span class="k">import</span> <span class="n">Executor</span>
<span class="kn">from</span> <span class="nn">ashpy.metrics.gan</span> <span class="k">import</span> <span class="n">DiscriminatorLoss</span><span class="p">,</span> <span class="n">EncoderLoss</span><span class="p">,</span> <span class="n">GeneratorLoss</span>
<span class="kn">from</span> <span class="nn">ashpy.modes</span> <span class="k">import</span> <span class="n">LogEvalMode</span>
<span class="kn">from</span> <span class="nn">ashpy.trainers.base_trainer</span> <span class="k">import</span> <span class="n">BaseTrainer</span>


<div class="viewcode-block" id="AdversarialTrainer"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html#ashpy.trainers.AdversarialTrainer">[docs]</a><span class="k">class</span> <span class="nc">AdversarialTrainer</span><span class="p">(</span><span class="n">BaseTrainer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Primitive Trainer for GANs subclassed from :class:`ashpy.trainers.BaseTrainer`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. testcode::</span>

<span class="sd">            import shutil</span>
<span class="sd">            import operator</span>
<span class="sd">            from ashpy.models.gans import Generator, Discriminator</span>
<span class="sd">            from ashpy.metrics import InceptionScore</span>
<span class="sd">            from ashpy.losses.gan import DiscriminatorMinMax, GeneratorBCE</span>

<span class="sd">            generator = Generator(</span>
<span class="sd">                layer_spec_input_res=(7, 7),</span>
<span class="sd">                layer_spec_target_res=(28, 28),</span>
<span class="sd">                kernel_size=(5, 5),</span>
<span class="sd">                initial_filters=32,</span>
<span class="sd">                filters_cap=16,</span>
<span class="sd">                channels=1,</span>
<span class="sd">            )</span>

<span class="sd">            discriminator = Discriminator(</span>
<span class="sd">                layer_spec_input_res=(28, 28),</span>
<span class="sd">                layer_spec_target_res=(7, 7),</span>
<span class="sd">                kernel_size=(5, 5),</span>
<span class="sd">                initial_filters=16,</span>
<span class="sd">                filters_cap=32,</span>
<span class="sd">                output_shape=1,</span>
<span class="sd">            )</span>

<span class="sd">            # Losses</span>
<span class="sd">            generator_bce = GeneratorBCE()</span>
<span class="sd">            minmax = DiscriminatorMinMax()</span>

<span class="sd">            # Real data</span>
<span class="sd">            batch_size = 2</span>
<span class="sd">            mnist_x, mnist_y = tf.zeros((100,28,28)), tf.zeros((100,))</span>

<span class="sd">            # Trainer</span>
<span class="sd">            epochs = 2</span>
<span class="sd">            logdir = &quot;testlog/adversarial&quot;</span>
<span class="sd">            metrics = [</span>
<span class="sd">                InceptionScore(</span>
<span class="sd">                    # Fake inception model</span>
<span class="sd">                    Discriminator(</span>
<span class="sd">                        layer_spec_input_res=(299, 299),</span>
<span class="sd">                        layer_spec_target_res=(7, 7),</span>
<span class="sd">                        kernel_size=(5, 5),</span>
<span class="sd">                        initial_filters=16,</span>
<span class="sd">                        filters_cap=32,</span>
<span class="sd">                        output_shape=10,</span>
<span class="sd">                    ),</span>
<span class="sd">                    #model_selection_operator=operator.gt,</span>
<span class="sd">                    logdir=logdir,</span>
<span class="sd">                )</span>
<span class="sd">            ]</span>
<span class="sd">            trainer = AdversarialTrainer(</span>
<span class="sd">                generator,</span>
<span class="sd">                discriminator,</span>
<span class="sd">                tf.optimizers.Adam(1e-4),</span>
<span class="sd">                tf.optimizers.Adam(1e-4),</span>
<span class="sd">                generator_bce,</span>
<span class="sd">                minmax,</span>
<span class="sd">                epochs,</span>
<span class="sd">                metrics,</span>
<span class="sd">                logdir,</span>
<span class="sd">            )</span>

<span class="sd">            # Dataset</span>
<span class="sd">            noise_dataset = tf.data.Dataset.from_tensors(0).repeat().map(</span>
<span class="sd">                lambda _: tf.random.normal(shape=(100,), dtype=tf.float32, mean=0.0, stddev=1)</span>
<span class="sd">            ).batch(batch_size).prefetch(1)</span>

<span class="sd">            # take only 2 samples to speed up tests</span>
<span class="sd">            real_data = (</span>
<span class="sd">                tf.data.Dataset.from_tensor_slices(</span>
<span class="sd">                (tf.expand_dims(mnist_x, -1), tf.expand_dims(mnist_y, -1))).take(batch_size)</span>
<span class="sd">                .batch(batch_size)</span>
<span class="sd">                .prefetch(1)</span>
<span class="sd">            )</span>

<span class="sd">            # Add noise in the same dataset, just by mapping.</span>
<span class="sd">            # The return type of the dataset must be: tuple(tuple(a,b), noise)</span>
<span class="sd">            dataset = real_data.map(</span>
<span class="sd">                lambda x, y: ((x, y), tf.random.normal(shape=(batch_size, 100)))</span>
<span class="sd">            )</span>

<span class="sd">            trainer(dataset)</span>
<span class="sd">            shutil.rmtree(logdir)</span>

<span class="sd">        .. testoutput::</span>

<span class="sd">            Initializing checkpoint.</span>
<span class="sd">            [1] Saved checkpoint: testlog/adversarial/ckpts/ckpt-1</span>
<span class="sd">            Epoch 1 completed.</span>
<span class="sd">            [2] Saved checkpoint: testlog/adversarial/ckpts/ckpt-2</span>
<span class="sd">            Epoch 2 completed.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AdversarialTrainer.__init__"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html#ashpy.trainers.AdversarialTrainer.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">discriminator</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">generator_optimizer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">discriminator_optimizer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">generator_loss</span><span class="p">:</span> <span class="n">Executor</span><span class="p">,</span>
        <span class="n">discriminator_loss</span><span class="p">:</span> <span class="n">Executor</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">logdir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;log&quot;</span><span class="p">),</span>
        <span class="n">post_process_callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">log_eval_mode</span><span class="o">=</span><span class="n">LogEvalMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span>
        <span class="n">global_step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;global_step&quot;</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a :py:class:`AdversarialTrainer`.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator (:py:class:`tf.keras.Model`): A :py:class:`tf.keras.Model` describing the Generator part of a GAN.</span>
<span class="sd">            discriminator (:py:class:`tf.keras.Model`): A :py:class:`tf.keras.Model` describing the Discriminator part of a GAN.</span>
<span class="sd">            generator_optimizer (:py:class:`tf.optimizers.Optimizer`): A :py:mod:`tf.optimizers` to use for the Generator.</span>
<span class="sd">            discriminator_optimizer (:py:class:`tf.optimizers.Optimizer`): A :py:mod:`tf.optimizers` to use for the Discriminator.</span>
<span class="sd">            generator_loss (:py:class:`ashpy.losses.executor.Executor`): A ash Executor to compute the loss of the Generator.</span>
<span class="sd">            discriminator_loss (:py:class:`ashpy.losses.executor.Executor`): A ash Executor to compute the loss of the Discriminator.</span>
<span class="sd">            epochs (int): number of training epochs.</span>
<span class="sd">            metrics: (List): list of :py:class:`tf.metrics` to measure on training and validation data.</span>
<span class="sd">            logdir: checkpoint and log directory.</span>
<span class="sd">            post_process_callback(:obj:`callable`): the function to postprocess the model output, if needed.</span>
<span class="sd">            log_eval_mode: models&#39; mode to use when evaluating and logging.</span>
<span class="sd">            global_step: tf.Variable that keeps track of the training steps.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :py:obj:`None`</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">,</span>
            <span class="n">log_eval_mode</span><span class="o">=</span><span class="n">log_eval_mode</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span>
            <span class="n">post_process_callback</span><span class="o">=</span><span class="n">post_process_callback</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span> <span class="o">=</span> <span class="n">discriminator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span> <span class="o">=</span> <span class="n">generator_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span> <span class="o">=</span> <span class="n">discriminator_loss</span>

        <span class="n">losses_metrics</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">DiscriminatorLoss</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">),</span>
            <span class="n">GeneratorLoss</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">metrics</span><span class="p">:</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">losses_metrics</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">losses_metrics</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span> <span class="o">=</span> <span class="n">metrics</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_gopt</span> <span class="o">=</span> <span class="n">generator_optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dopt</span> <span class="o">=</span> <span class="n">discriminator_optimizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gopt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dopt</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># pylint: disable=unidiomatic-typecheck</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="n">AdversarialTrainer</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_restore_or_init</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="n">GANContext</span><span class="p">(</span>
            <span class="n">generator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">,</span>
            <span class="n">discriminator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="p">,</span>
            <span class="n">log_eval_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span>
            <span class="n">ckpt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ckpt</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="AdversarialTrainer.train_step"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html#ashpy.trainers.AdversarialTrainer.train_step">[docs]</a>    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_xy</span><span class="p">,</span> <span class="n">g_inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train step for the AdversarialTrainer.</span>

<span class="sd">        Args:</span>
<span class="sd">            real_xy: input batch as extracted from the input dataset.</span>
<span class="sd">                     (features, label) pair.</span>
<span class="sd">            g_inputs: batch of generator_input as generated from the input dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            d_loss, g_loss, fake: discriminator, generator loss values. fake is the generator output.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">real_x</span><span class="p">,</span> <span class="n">real_y</span> <span class="o">=</span> <span class="n">real_xy</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">g_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">g_inputs</span><span class="p">,</span> <span class="n">real_y</span><span class="p">]</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span><span class="n">g_inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">d_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">,</span> <span class="n">fake</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="n">real_x</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">real_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="n">g_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">,</span> <span class="n">fake</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="n">real_x</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">real_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="c1"># check that we have some trainable_variables</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="c1"># calculate the gradient</span>
        <span class="n">d_gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">d_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">g_gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">g_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

        <span class="c1"># delete the tape since it&#39;s persistent</span>
        <span class="k">del</span> <span class="n">tape</span>

        <span class="c1"># apply the gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dopt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">d_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gopt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">g_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">d_loss</span><span class="p">,</span> <span class="n">g_loss</span><span class="p">,</span> <span class="n">fake</span></div>

<div class="viewcode-block" id="AdversarialTrainer._train_step"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html#ashpy.trainers.AdversarialTrainer._train_step">[docs]</a>    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">_train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Training step with the distribution strategy.&quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribute_strategy</span><span class="o">.</span><span class="n">experimental_run_v2</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">example</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>

        <span class="n">per_replica_losses</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">per_replica_losses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">per_replica_losses</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">),</span>
            <span class="n">fake</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="AdversarialTrainer._measure_performance"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html#ashpy.trainers.AdversarialTrainer._measure_performance">[docs]</a>    <span class="k">def</span> <span class="nf">_measure_performance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Measure performance on dataset</span>
<span class="sd">        Args:</span>
<span class="sd">            dataset (:py:obj:`tf.data.Dataset`):</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">GANContext</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">generator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">,</span>
            <span class="n">discriminator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="p">,</span>
            <span class="n">generator_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span><span class="p">,</span>
            <span class="n">discriminator_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="p">,</span>
            <span class="n">log_eval_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="p">,</span>
            <span class="n">ckpt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ckpt</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">context</span><span class="o">.</span><span class="n">measure_metrics</span><span class="p">()</span>
        <span class="n">context</span><span class="o">.</span><span class="n">model_selection</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_metrics_and_reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="AdversarialTrainer.call"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.AdversarialTrainer.html#ashpy.trainers.AdversarialTrainer.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the adversarial training.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (:py:obj:`tf.data.Dataset`): The adversarial training dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">current_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_update_global_batch_size</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span><span class="p">])</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">wrap</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">unbatch</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">gen_inputs</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;real_x&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;real_y&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>

            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">current_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epochs</span><span class="p">):</span>
                <span class="n">distribute_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribute_strategy</span><span class="o">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span>
                    <span class="n">dataset</span>
                <span class="p">)</span>

                <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">distribute_dataset</span><span class="p">:</span>
                    <span class="n">d_loss</span><span class="p">,</span> <span class="n">g_loss</span><span class="p">,</span> <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># print statistics</span>
                    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="mi">0</span><span class="p">):</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                            <span class="n">f</span><span class="s2">&quot;[{self._global_step.numpy()}] g_loss: </span><span class="si">{g_loss}</span><span class="s2"> - d_loss: </span><span class="si">{d_loss}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_measure_performance</span><span class="p">(</span>
                            <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">example</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_global_batch_size</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

                <span class="c1"># here we have finished an epoch</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_epoch_completed</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span> <span class="o">==</span> <span class="n">LogEvalMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;generator&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span><span class="n">gen_inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span> <span class="o">==</span> <span class="n">LogEvalMode</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;generator&quot;</span><span class="p">,</span> <span class="n">fake</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="EncoderTrainer"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html#ashpy.trainers.EncoderTrainer">[docs]</a><span class="k">class</span> <span class="nc">EncoderTrainer</span><span class="p">(</span><span class="n">AdversarialTrainer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Primitive Trainer for GANs using an Encoder sub-network.</span>
<span class="sd">    The implementation is thought to be used with the BCE losses. To use another loss function</span>
<span class="sd">    consider subclassing the model and overriding the train_step method.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. testcode::</span>

<span class="sd">            import shutil</span>
<span class="sd">            import operator</span>
<span class="sd">            from ashpy.metrics import EncodingAccuracy</span>
<span class="sd">            from ashpy.losses.gan import DiscriminatorMinMax, GeneratorBCE, EncoderBCE</span>

<span class="sd">            def real_gen():</span>
<span class="sd">                label = 0</span>
<span class="sd">                for _ in tf.range(100):</span>
<span class="sd">                    yield ((10.0,), (label,))</span>

<span class="sd">            latent_dim = 100</span>

<span class="sd">            generator = tf.keras.Sequential([tf.keras.layers.Dense(1)])</span>

<span class="sd">            left_input = tf.keras.layers.Input(shape=(1,))</span>
<span class="sd">            left = tf.keras.layers.Dense(10, activation=tf.nn.elu)(left_input)</span>

<span class="sd">            right_input = tf.keras.layers.Input(shape=(latent_dim,))</span>
<span class="sd">            right = tf.keras.layers.Dense(10, activation=tf.nn.elu)(right_input)</span>

<span class="sd">            net = tf.keras.layers.Concatenate()([left, right])</span>
<span class="sd">            out = tf.keras.layers.Dense(1)(net)</span>

<span class="sd">            discriminator = tf.keras.Model(inputs=[left_input, right_input], outputs=[out])</span>

<span class="sd">            encoder = tf.keras.Sequential([tf.keras.layers.Dense(latent_dim)])</span>

<span class="sd">            # Losses</span>
<span class="sd">            generator_bce = GeneratorBCE()</span>
<span class="sd">            encoder_bce = EncoderBCE()</span>
<span class="sd">            minmax = DiscriminatorMinMax()</span>

<span class="sd">            epochs = 2</span>

<span class="sd">            # Fake pre-trained classifier</span>
<span class="sd">            num_classes = 1</span>
<span class="sd">            classifier = tf.keras.Sequential(</span>
<span class="sd">                [tf.keras.layers.Dense(10), tf.keras.layers.Dense(num_classes)]</span>
<span class="sd">            )</span>

<span class="sd">            logdir = &quot;testlog/adversarial/encoder&quot;</span>

<span class="sd">            metrics = [</span>
<span class="sd">                EncodingAccuracy(</span>
<span class="sd">                    classifier,</span>
<span class="sd">                    # model_selection_operator=operator.gt,</span>
<span class="sd">                    logdir=logdir</span>
<span class="sd">                )</span>
<span class="sd">            ]</span>

<span class="sd">            trainer = EncoderTrainer(</span>
<span class="sd">                generator=generator,</span>
<span class="sd">                discriminator=discriminator,</span>
<span class="sd">                encoder=encoder,</span>
<span class="sd">                discriminator_optimizer=tf.optimizers.Adam(1e-4),</span>
<span class="sd">                generator_optimizer=tf.optimizers.Adam(1e-5),</span>
<span class="sd">                encoder_optimizer=tf.optimizers.Adam(1e-6),</span>
<span class="sd">                generator_loss=generator_bce,</span>
<span class="sd">                discriminator_loss=minmax,</span>
<span class="sd">                encoder_loss=encoder_bce,</span>
<span class="sd">                epochs=epochs,</span>
<span class="sd">                metrics=metrics,</span>
<span class="sd">                logdir=logdir,</span>
<span class="sd">            )</span>

<span class="sd">            batch_size = 10</span>
<span class="sd">            discriminator_input = tf.data.Dataset.from_generator(</span>
<span class="sd">                real_gen, (tf.float32, tf.int64), ((1), (1))</span>
<span class="sd">            ).batch(batch_size)</span>

<span class="sd">            dataset = discriminator_input.map(</span>
<span class="sd">                lambda x, y: ((x, y), tf.random.normal(shape=(batch_size, latent_dim)))</span>
<span class="sd">            )</span>

<span class="sd">            trainer(dataset)</span>

<span class="sd">            shutil.rmtree(logdir)</span>

<span class="sd">        .. testoutput::</span>

<span class="sd">            Initializing checkpoint.</span>
<span class="sd">            [10] Saved checkpoint: testlog/adversarial/encoder/ckpts/ckpt-1</span>
<span class="sd">            Epoch 1 completed.</span>
<span class="sd">            [20] Saved checkpoint: testlog/adversarial/encoder/ckpts/ckpt-2</span>
<span class="sd">            Epoch 2 completed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="EncoderTrainer.__init__"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html#ashpy.trainers.EncoderTrainer.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">discriminator</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
        <span class="n">generator_optimizer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">discriminator_optimizer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">encoder_optimizer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">generator_loss</span><span class="p">:</span> <span class="n">Executor</span><span class="p">,</span>
        <span class="n">discriminator_loss</span><span class="p">:</span> <span class="n">Executor</span><span class="p">,</span>
        <span class="n">encoder_loss</span><span class="p">:</span> <span class="n">Executor</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">,</span>
        <span class="n">metrics</span><span class="p">,</span>
        <span class="n">logdir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;log&quot;</span><span class="p">),</span>
        <span class="n">post_process_callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">log_eval_mode</span><span class="o">=</span><span class="n">LogEvalMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span>
        <span class="n">global_step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;global_step&quot;</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a :py:class:`EncoderTrainer`.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator (:py:class:`tf.keras.Model`): A :py:class:`tf.keras.Model` describing the Generator part of a GAN.</span>
<span class="sd">            discriminator (:py:class:`tf.keras.Model`): A :py:class:`tf.keras.Model` describing the Discriminator part of a GAN.</span>
<span class="sd">            encoder (:py:class:`tf.keras.Model`): A :py:class:`tf.keras.Model` describing the Encoder part of a GAN.</span>
<span class="sd">            generator_optimizer (:py:class:`tf.optimizers.Optimizer`): A :py:mod:`tf.optimizers` to use for the Generator.</span>
<span class="sd">            discriminator_optimizer (:py:class:`tf.optimizers.Optimizer`): A :py:mod:`tf.optimizers` to use for the Discriminator.</span>
<span class="sd">            encoder_optimizer (:py:class:`tf.optimizers.Optimizer`): A :py:mod:`tf.optimizers` to use for the Encoder.</span>
<span class="sd">            generator_loss (:py:class:`ashpy.losses.executor.Executor`): A ash Executor to compute the loss of the Generator.</span>
<span class="sd">            discriminator_loss (:py:class:`ashpy.losses.executor.Executor`): A ash Executor to compute the loss of the Discriminator.</span>
<span class="sd">            encoder_loss (:py:class:`ashpy.losses.executor.Executor`): A ash Executor to compute the loss of the Discriminator.</span>
<span class="sd">            epochs (int): number of training epochs.</span>
<span class="sd">            metrics: (List): list of tf.metrics to measure on training and validation data.</span>
<span class="sd">            logdir: checkpoint and log directory.</span>
<span class="sd">            post_process_callback(:obj:`callable`): a function to post-process the output.</span>
<span class="sd">            log_eval_mode: models&#39; mode to use when evaluating and logging.</span>
<span class="sd">            global_step: tf.Variable that keeps track of the training steps.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
            <span class="n">discriminator</span><span class="o">=</span><span class="n">discriminator</span><span class="p">,</span>
            <span class="n">generator_optimizer</span><span class="o">=</span><span class="n">generator_optimizer</span><span class="p">,</span>
            <span class="n">discriminator_optimizer</span><span class="o">=</span><span class="n">discriminator_optimizer</span><span class="p">,</span>
            <span class="n">generator_loss</span><span class="o">=</span><span class="n">generator_loss</span><span class="p">,</span>
            <span class="n">discriminator_loss</span><span class="o">=</span><span class="n">discriminator_loss</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
            <span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">,</span>
            <span class="n">post_process_callback</span><span class="o">=</span><span class="n">post_process_callback</span><span class="p">,</span>
            <span class="n">log_eval_mode</span><span class="o">=</span><span class="n">log_eval_mode</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dopt</span> <span class="o">=</span> <span class="n">discriminator_optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eopt</span> <span class="o">=</span> <span class="n">encoder_optimizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_e_loss</span> <span class="o">=</span> <span class="n">encoder_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_e_loss</span><span class="o">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EncoderLoss</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eopt</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_restore_or_init</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="n">GANEncoderContext</span><span class="p">(</span>
            <span class="n">generator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">,</span>
            <span class="n">discriminator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="p">,</span>
            <span class="n">encoder_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="p">,</span>
            <span class="n">log_eval_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="p">,</span>
            <span class="n">ckpt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ckpt</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="EncoderTrainer.train_step"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html#ashpy.trainers.EncoderTrainer.train_step">[docs]</a>    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_xy</span><span class="p">,</span> <span class="n">g_inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adversarial training step.</span>

<span class="sd">        Args:</span>
<span class="sd">            real_xy: input batch as extracted from the discriminator input dataset.</span>
<span class="sd">                     (features, label) pair</span>
<span class="sd">            g_inputs: batch of noise as generated by the generator input dataset.</span>
<span class="sd">        Returns:</span>
<span class="sd">            d_loss, g_loss, e_loss: discriminator, generator, encoder loss values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">real_x</span><span class="p">,</span> <span class="n">real_y</span> <span class="o">=</span> <span class="n">real_xy</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">g_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">g_inputs</span><span class="p">,</span> <span class="n">real_y</span><span class="p">]</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span><span class="n">g_inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">g_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">,</span> <span class="n">fake</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="n">real_x</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">real_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="n">d_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">,</span> <span class="n">fake</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="n">real_x</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">real_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="n">e_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">,</span> <span class="n">fake</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="n">real_x</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">real_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="n">g_gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">g_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">d_gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">d_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">e_gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">e_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">tape</span>

        <span class="c1"># Only for logging in special cases (out of tape)</span>
        <span class="n">generator_of_encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="p">(</span><span class="n">real_x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dopt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">d_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gopt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
            <span class="nb">zip</span><span class="p">(</span><span class="n">g_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eopt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">e_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">d_loss</span><span class="p">,</span> <span class="n">g_loss</span><span class="p">,</span> <span class="n">e_loss</span><span class="p">,</span> <span class="n">fake</span><span class="p">,</span> <span class="n">generator_of_encoder</span></div>

<div class="viewcode-block" id="EncoderTrainer._train_step"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html#ashpy.trainers.EncoderTrainer._train_step">[docs]</a>    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">_train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The training step that uses the distribution strategy.&quot;&quot;&quot;</span>

        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribute_strategy</span><span class="o">.</span><span class="n">experimental_run_v2</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">example</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>

        <span class="n">per_replica_losses</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">generator_of_encoder</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">per_replica_losses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">per_replica_losses</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="p">(</span><span class="n">per_replica_losses</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">),</span>
            <span class="n">fake</span><span class="p">,</span>
            <span class="n">generator_of_encoder</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="EncoderTrainer._measure_performance"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html#ashpy.trainers.EncoderTrainer._measure_performance">[docs]</a>    <span class="k">def</span> <span class="nf">_measure_performance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">GANEncoderContext</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">generator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">,</span>
            <span class="n">discriminator_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_discriminator</span><span class="p">,</span>
            <span class="n">encoder_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="p">,</span>
            <span class="n">generator_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span><span class="p">,</span>
            <span class="n">discriminator_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span><span class="p">,</span>
            <span class="n">encoder_loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_e_loss</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="p">,</span>
            <span class="n">ckpt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ckpt</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">context</span><span class="o">.</span><span class="n">measure_metrics</span><span class="p">()</span>
        <span class="n">context</span><span class="o">.</span><span class="n">model_selection</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_metrics_and_reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="EncoderTrainer.call"><a class="viewcode-back" href="../../../_autosummary/trainers/gan/ashpy.trainers.gan.EncoderTrainer.html#ashpy.trainers.EncoderTrainer.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the adversarial training.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (:py:class:`tf.data.Dataset`): The adversarial training dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">current_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_update_global_batch_size</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_g_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_loss</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">wrap</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">unbatch</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">gen_inputs</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;real_x&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;real_y&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>

            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">current_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epochs</span><span class="p">):</span>
                <span class="n">distribute_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribute_strategy</span><span class="o">.</span><span class="n">experimental_distribute_dataset</span><span class="p">(</span>
                    <span class="n">dataset</span>
                <span class="p">)</span>

                <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">distribute_dataset</span><span class="p">:</span>
                    <span class="n">d_loss</span><span class="p">,</span> <span class="n">g_loss</span><span class="p">,</span> <span class="n">e_loss</span><span class="p">,</span> <span class="n">fake</span><span class="p">,</span> <span class="n">generator_of_encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">(</span>
                        <span class="n">example</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="mi">0</span><span class="p">):</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                            <span class="n">f</span><span class="s2">&quot;[{self._global_step.numpy()}] g_loss: </span><span class="si">{g_loss}</span><span class="s2"> - &quot;</span>
                            <span class="n">f</span><span class="s2">&quot;d_loss: </span><span class="si">{d_loss}</span><span class="s2"> - e_loss: </span><span class="si">{e_loss}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_measure_performance</span><span class="p">(</span>
                            <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">example</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_global_batch_size</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_epoch_completed</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span> <span class="o">==</span> <span class="n">LogEvalMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;generator&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span><span class="n">gen_inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span>
                        <span class="s2">&quot;generator_of_encoder&quot;</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span>
                        <span class="p">),</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_eval_mode</span> <span class="o">==</span> <span class="n">LogEvalMode</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;generator&quot;</span><span class="p">,</span> <span class="n">fake</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="s2">&quot;generator_of_encoder&quot;</span><span class="p">,</span> <span class="n">generator_of_encoder</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019 Zuru Tech HK Limited, All rights reserved.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>